{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9efa471-1def-4e16-b903-1a221ccf31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Michigan Ross Faculty Scraper - For Jupyter Notebook\n",
    "# Run directly in Jupyter cell\n",
    "\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "import random\n",
    "\n",
    "# Allow asyncio in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def human_delay(min_sec=2, max_sec=5):\n",
    "    \"\"\"Random delay\"\"\"\n",
    "    await asyncio.sleep(random.uniform(min_sec, max_sec))\n",
    "\n",
    "async def scrape_faculty_page(page, page_num):\n",
    "    \"\"\"Scrape faculty list from a single page\"\"\"\n",
    "    # Page number starts from 0, so subtract 1\n",
    "    actual_page = page_num - 1\n",
    "    url = f\"https://michiganross.umich.edu/faculty-research/directory?page={actual_page}\"\n",
    "    print(f\"Visiting page {page_num} (URL: page={actual_page})\")\n",
    "    \n",
    "    try:\n",
    "        await page.goto(url, wait_until='load', timeout=120000)\n",
    "    except:\n",
    "        print(\"Page load timeout, trying to continue...\")\n",
    "    \n",
    "    await asyncio.sleep(5)\n",
    "    \n",
    "    # Scroll page\n",
    "    try:\n",
    "        await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        await human_delay(1, 2)\n",
    "        await page.evaluate(\"window.scrollTo(0, 0)\")\n",
    "        await human_delay(1, 2)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Extract all faculty links\n",
    "    faculty_links = await page.query_selector_all('a[href*=\"/faculty-research/faculty/\"]')\n",
    "    \n",
    "    faculty_data = {}\n",
    "    for link in faculty_links:\n",
    "        try:\n",
    "            href = await link.get_attribute('href')\n",
    "            if href:\n",
    "                # Convert relative path to full URL\n",
    "                if not href.startswith('http'):\n",
    "                    href = f\"https://michiganross.umich.edu{href}\"\n",
    "                \n",
    "                name = await link.inner_text()\n",
    "                name = name.strip()\n",
    "                \n",
    "                # Skip empty text and duplicate URLs\n",
    "                if name and href not in faculty_data:\n",
    "                    faculty_data[href] = {\n",
    "                        'name': name,\n",
    "                        'profile_url': href,\n",
    "                        'title': 'N/A',\n",
    "                        'department': 'N/A'\n",
    "                    }\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Found {len(faculty_data)} faculty on page {page_num}\")\n",
    "    return list(faculty_data.values())\n",
    "\n",
    "async def scrape_publications(page, profile_url, name):\n",
    "    \"\"\"Scrape publications for a single faculty member\"\"\"\n",
    "    print(f\"  Visiting: {name}\")\n",
    "    \n",
    "    try:\n",
    "        try:\n",
    "            await page.goto(profile_url, wait_until='load', timeout=120000)\n",
    "        except:\n",
    "            print(f\"    Load timeout, trying to continue...\")\n",
    "        \n",
    "        await asyncio.sleep(3)\n",
    "        \n",
    "        # Scroll multiple times\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "                await human_delay(1, 2)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Extract page text\n",
    "        page_text = await page.inner_text('body')\n",
    "        \n",
    "        publications = []\n",
    "        \n",
    "        # Find publication elements\n",
    "        if 'article' in page_text.lower() or 'publication' in page_text.lower():\n",
    "            pub_elements = await page.query_selector_all('[class*=\"publication\"], [class*=\"article\"]')\n",
    "            \n",
    "            for pub in pub_elements:\n",
    "                try:\n",
    "                    text = await pub.inner_text()\n",
    "                    if text and len(text) > 30:\n",
    "                        publications.append(text.strip())\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        print(f\"    Found {len(publications)} publications\")\n",
    "        return publications\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"    Error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "async def run_scraper(total_pages=1, fetch_publications=False):\n",
    "    \"\"\"\n",
    "    Main function\n",
    "    \n",
    "    Parameters:\n",
    "        total_pages: Number of pages to scrape (1-9)\n",
    "        fetch_publications: Whether to fetch publications (True/False)\n",
    "    \"\"\"\n",
    "    async with async_playwright() as p:\n",
    "        # Launch browser\n",
    "        browser = await p.chromium.launch(\n",
    "            headless=False,\n",
    "            args=[\n",
    "                '--disable-blink-features=AutomationControlled',\n",
    "                '--disable-dev-shm-usage',\n",
    "                '--no-sandbox'\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Create context\n",
    "        context = await browser.new_context(\n",
    "            viewport={'width': 1920, 'height': 1080},\n",
    "            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'\n",
    "        )\n",
    "        \n",
    "        # Anti-detection\n",
    "        await context.add_init_script(\"\"\"\n",
    "            Object.defineProperty(navigator, 'webdriver', {\n",
    "                get: () => undefined\n",
    "            });\n",
    "        \"\"\")\n",
    "        \n",
    "        page = await context.new_page()\n",
    "        \n",
    "        try:\n",
    "            print(\"=\"*70)\n",
    "            print(\"Opening website...\")\n",
    "            print(\"If CAPTCHA appears, please complete it manually\")\n",
    "            print(\"Script will continue automatically after 10 seconds\")\n",
    "            print(\"=\"*70 + \"\\n\")\n",
    "            \n",
    "            # First visit - use relaxed wait strategy\n",
    "            try:\n",
    "                # First page is page=0\n",
    "                await page.goto(\"https://michiganross.umich.edu/faculty-research/directory?page=0\", \n",
    "                              wait_until='load', timeout=120000)\n",
    "            except:\n",
    "                print(\"Page load timeout, but content may have loaded\")\n",
    "            \n",
    "            # Wait for page to stabilize\n",
    "            await asyncio.sleep(10)\n",
    "            \n",
    "            print(\"Starting data scraping...\\n\")\n",
    "            \n",
    "            all_data = []\n",
    "            \n",
    "            # Scrape each page\n",
    "            for page_num in range(1, total_pages + 1):\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"Page {page_num}/{total_pages}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                \n",
    "                faculty_list = await scrape_faculty_page(page, page_num)\n",
    "                \n",
    "                # Process each faculty member\n",
    "                for i, faculty in enumerate(faculty_list, 1):\n",
    "                    print(f\"[{i}/{len(faculty_list)}] {faculty['name']}\")\n",
    "                    \n",
    "                    if fetch_publications:\n",
    "                        pubs = await scrape_publications(page, faculty['profile_url'], faculty['name'])\n",
    "                        faculty['publications'] = '\\n\\n---\\n\\n'.join(pubs) if pubs else 'No publications found'\n",
    "                        await human_delay(3, 6)\n",
    "                    else:\n",
    "                        faculty['publications'] = 'Not fetched'\n",
    "                    \n",
    "                    all_data.append(faculty)\n",
    "                    \n",
    "                    # Save every 10 records\n",
    "                    if len(all_data) % 10 == 0:\n",
    "                        df = pd.DataFrame(all_data)\n",
    "                        df.to_csv('umich_temp.csv', index=False, encoding='utf-8-sig')\n",
    "                        print(f\"    Saved {len(all_data)} records\")\n",
    "                \n",
    "                # Delay between pages\n",
    "                if page_num < total_pages:\n",
    "                    await human_delay(5, 8)\n",
    "            \n",
    "            # Save final data\n",
    "            if all_data:\n",
    "                df = pd.DataFrame(all_data)\n",
    "                df.to_csv('umich_ross_final.csv', index=False, encoding='utf-8-sig')\n",
    "                \n",
    "                try:\n",
    "                    df.to_excel('umich_ross_final.xlsx', index=False, engine='openpyxl')\n",
    "                except:\n",
    "                    print(\"Cannot save Excel, CSV only\")\n",
    "                \n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(f\"Complete! Total {len(all_data)} faculty members\")\n",
    "                print(f\"Data saved to:\")\n",
    "                print(f\"   - umich_ross_final.csv\")\n",
    "                if 'openpyxl' in dir():\n",
    "                    print(f\"   - umich_ross_final.xlsx\")\n",
    "                print(f\"{'='*70}\\n\")\n",
    "                \n",
    "                return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            return None\n",
    "        finally:\n",
    "            await browser.close()\n",
    "\n",
    "# =============================================================================\n",
    "# Scrape all 9 pages directly\n",
    "# =============================================================================\n",
    "\n",
    "# Scrape all 9 pages of faculty basic information (without publications)\n",
    "print(\"Starting to scrape all 9 pages of Michigan Ross faculty...\\n\")\n",
    "df_all = await run_scraper(total_pages=9, fetch_publications=False)\n",
    "\n",
    "# View results\n",
    "if df_all is not None:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Scraping complete! Statistics:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total faculty: {len(df_all)}\")\n",
    "    print(f\"Files saved:\")\n",
    "    print(f\"   - umich_ross_final.csv\")\n",
    "    print(f\"   - umich_ross_final.xlsx\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    print(\"Data preview:\")\n",
    "    display(df_all.head(10))\n",
    "    \n",
    "    print(f\"\\nTotal {len(df_all)} faculty members\")\n",
    "else:\n",
    "    print(\"Scraping failed, please check error messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb85e211-9d0c-43c4-a3f6-d224cc477d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 225\n",
      "Total columns: 5\n",
      "\n",
      "Column names: ['name', 'profile_url', 'title', 'department', 'publications']\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>profile_url</th>\n",
       "      <th>title</th>\n",
       "      <th>department</th>\n",
       "      <th>publications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allan Afuah</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hyun-Soo Ahn</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheri Alexander</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samuel Anderson</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Angell</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ravi Anupindi</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anocha Aribarg</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Daphne Armstrong</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sue Ashford</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kate Astashkina</td>\n",
       "      <td>https://michiganross.umich.edu/faculty-researc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not fetched</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                        profile_url  title  \\\n",
       "0       Allan Afuah  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "1      Hyun-Soo Ahn  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "2   Cheri Alexander  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "3   Samuel Anderson  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "4        Amy Angell  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "5     Ravi Anupindi  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "6    Anocha Aribarg  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "7  Daphne Armstrong  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "8       Sue Ashford  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "9   Kate Astashkina  https://michiganross.umich.edu/faculty-researc...    NaN   \n",
       "\n",
       "   department publications  \n",
       "0         NaN  Not fetched  \n",
       "1         NaN  Not fetched  \n",
       "2         NaN  Not fetched  \n",
       "3         NaN  Not fetched  \n",
       "4         NaN  Not fetched  \n",
       "5         NaN  Not fetched  \n",
       "6         NaN  Not fetched  \n",
       "7         NaN  Not fetched  \n",
       "8         NaN  Not fetched  \n",
       "9         NaN  Not fetched  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read Excel files\n",
    "df = pd.read_excel('umich_ross_final.xlsx')\n",
    "\n",
    "#  Display basic information\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumn names: {df.columns.tolist()}\\n\")\n",
    "\n",
    "# Display the first 10 lines\n",
    "print(\"First 10 rows:\")\n",
    "display(df.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
